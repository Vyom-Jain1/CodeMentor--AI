<<<<<<< HEAD
# Server Configuration
NODE_ENV=development
PORT=5000

# MongoDB Configuration
MONGO_URI=mongodb://localhost:27017/codementor

# JWT Configuration
JWT_SECRET=your_jwt_secret_here
JWT_EXPIRE=30d

# Rate Limiting
RATE_LIMIT_WINDOW=900000  # 15 minutes in milliseconds
RATE_LIMIT_MAX_REQUESTS=100

# AI Provider Configuration
# OpenAI - Optional, used for advanced code analysis
OPENAI_API_KEY=your_openai_api_key_here

# Hugging Face - Required for code generation and analysis
# Get your API key from: https://huggingface.co/settings/tokens
HF_API_KEY=your_huggingface_api_key_here
HF_API_URL=https://api-inference.huggingface.co/models/bigcode/starcoder

# Socket.IO Configuration
SOCKET_PING_TIMEOUT=60000
SOCKET_PING_INTERVAL=25000

# CORS Configuration
CORS_ORIGIN=http://localhost:3000

# Security
MAX_REQUEST_SIZE=50mb
=======
NODE_ENV=development
PORT=5000
MONGO_URI=mongodb://localhost:27017/codementor
JWT_SECRET=your-super-secret-jwt-key-here-make-it-long-and-random
JWT_EXPIRE=30d

# AI Configuration
AI_PROVIDER=openai
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_API_URL=https://api.openai.com/v1/chat/completions
OPENAI_MODEL=gpt-3.5-turbo

# Ollama Configuration (Alternative)
OLLAMA_API_URL=http://localhost:11434/api/generate
OLLAMA_MODEL=codellama:7b

# Hugging Face Configuration (Alternative)
HF_API_KEY=your-huggingface-api-key
HF_API_URL=https://api-inference.huggingface.co/models/bigcode/starcoder

# Code Execution
CODE_EXECUTION_PROVIDER=piston
PISTON_API_URL=https://emkc.org/api/v2/piston/execute

# Rate Limiting
RATE_LIMIT_WINDOW=60000
RATE_LIMIT_MAX_REQUESTS=20
>>>>>>> 7f8f4cf10e81592f512281552bd44bd45ba50813
